{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libraries\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "## remove this line when running script from terminal, keep it when running notebooks\n",
    "%matplotlib inline \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "import graphviz # to plot the decission tree\n",
    "import os # to join pathrs, etc..\n",
    "import pickle # to store the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define filenames and sutff\n",
    "peaks_path = 'output'\n",
    "labels_path = 'all_labels.txt'\n",
    "\n",
    "# reads labels into a df\n",
    "train_labels_df = pd.read_csv(labels_path, sep=\"\\t\")\n",
    "## take care because there are duplicates!!!!!!!!!\n",
    "train_labels_df = train_labels_df.drop_duplicates(subset='file').reset_index(drop=True)\n",
    "## adding a column for the labels with the id of the label\n",
    "labels = train_labels_df['candy'].unique()\n",
    "train_labels_df['candy_id'] = np.where(labels == train_labels_df['candy'][:,None])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 23 files with peaks\n"
     ]
    }
   ],
   "source": [
    "print \"Total of %i files with peaks\"% train_labels_df['file'].shape[0]\n",
    "\n",
    "peaks_files = [ os.path.join(peaks_path, file) for file in train_labels_df['file'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_folder = 'results'\n",
    "\n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "\n",
    "## Step 7\n",
    "\n",
    "Create a peak alignment matrix with the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#peaks_files.pop(1)\n",
    "#train_labels_df = train_labels_df.drop(1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files( paths ):\n",
    "    # reads all the files\n",
    "    raw_peaks = [pd.read_csv(path, sep=\"\\t\") for path in paths ]\n",
    "    # combines them all in one dataframe\n",
    "    df = pd.concat(raw_peaks).reset_index(drop=True)\n",
    "    # converts peak_name column into integers\n",
    "    peaks = [ int(peak.replace('p','')) for peak in df['peak_name']] \n",
    "    df['peak_name'] = peaks\n",
    "    return df\n",
    "\n",
    "def align_peaks( data, peaks=90):\n",
    "    KM = KMeans(n_clusters=peaks, n_init=100)\n",
    "    KM.fit(data[['t', 'r']])\n",
    "    data['cluster_id'] = KM.labels_\n",
    "    return KM, data\n",
    "    \n",
    "def create_train_matrix( data , n_clusters):\n",
    "    total_clusters = n_clusters\n",
    "    d = { colname: [0] * total_clusters for colname in data['measurement_name'].unique() }\n",
    "    matrix = pd.DataFrame(data=d)\n",
    "    ## fill the matrix\n",
    "    for name in data['measurement_name'].unique():\n",
    "        patient = data[data['measurement_name'] == name]\n",
    "        clusters = patient['cluster_id']\n",
    "        #for cluster in clusters:\n",
    "        matrix[name][clusters] = 1\n",
    "    \n",
    "    return matrix.transpose()\n",
    "\n",
    "raw_df = read_files( peaks_files )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLUSTERS = int(np.average([ raw_df[raw_df['measurement_name'] == name].shape[0] for name in raw_df['measurement_name'].unique()]) * 1.5)\n",
    "CLUSTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing head of the matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BD18_1711291646_ims.csv</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BD18_1711291652_ims.csv</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BD18_1711291656_ims.csv</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BD18_1711291702_ims.csv</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BD18_1711291705_ims.csv</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0   1   2   3   4   5   6   7   8   9  ...  87  88  \\\n",
       "BD18_1711291646_ims.csv   0   0   1   0   0   1   1   0   1   0 ...   0   0   \n",
       "BD18_1711291652_ims.csv   0   1   1   0   1   1   1   0   1   0 ...   0   0   \n",
       "BD18_1711291656_ims.csv   0   1   1   0   0   0   1   0   1   0 ...   0   0   \n",
       "BD18_1711291702_ims.csv   1   0   1   0   1   0   1   0   1   0 ...   0   0   \n",
       "BD18_1711291705_ims.csv   0   0   1   0   0   1   1   0   1   0 ...   0   0   \n",
       "\n",
       "                         89  90  91  92  93  94  95  96  \n",
       "BD18_1711291646_ims.csv   0   0   0   0   0   1   0   0  \n",
       "BD18_1711291652_ims.csv   0   0   0   0   0   0   0   0  \n",
       "BD18_1711291656_ims.csv   0   1   0   0   0   0   0   0  \n",
       "BD18_1711291702_ims.csv   0   0   0   0   0   1   0   1  \n",
       "BD18_1711291705_ims.csv   0   0   0   0   0   1   0   0  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means, aligned_df = align_peaks( raw_df ,peaks = CLUSTERS)\n",
    "train_matrix_df = create_train_matrix(aligned_df, k_means.n_clusters)\n",
    "\n",
    "print \"Showing head of the matrix\"\n",
    "train_matrix_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8\n",
    "\n",
    "Train random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_rf = RandomForestClassifier(n_estimators=20)\n",
    "g_rf = g_rf.fit(train_matrix_df.as_matrix(), train_labels_df['candy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = g_rf.predict(train_matrix_df.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  0],\n",
       "       [ 0, 12]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(train_labels_df['candy'], prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9\n",
    "\n",
    "Implement 5-fold cross validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_cross_fold_validation( data, labels, k=5):\n",
    "    \"\"\"Returns the predictions and the indexes of each test slice\"\"\"\n",
    "    rf = RandomForestClassifier(n_estimators=25)\n",
    "    predictions, indexes = [], []\n",
    "    size = data.shape[0]\n",
    "    step_size = int(size / 5)\n",
    "    for i in range(k):\n",
    "        indexes.append(range(i*k, min(i*k + k, size)))\n",
    "        xtrain = np.array(data)\n",
    "        ytrain = np.array(labels)\n",
    "\n",
    "        # picks test slices\n",
    "        xtest = xtrain[i*k:i*k + k]\n",
    "        ytest = ytrain[i*k:i*k + k]\n",
    "\n",
    "        # removes test slices from the training sets\n",
    "        xtrain = np.delete(xtrain, np.s_[i*k:i*k + k], axis=0)\n",
    "        ytrain = np.delete(ytrain, np.s_[i*k:i*k + k], axis=0)\n",
    "\n",
    "        \n",
    "        rf = rf.fit(xtrain, ytrain)\n",
    "        prediction = rf.predict(xtest)\n",
    "\n",
    "        predictions.append(prediction.tolist())\n",
    "        \n",
    "    return np.array(predictions), np.array(indexes)\n",
    "\n",
    "pred, indexes = k_cross_fold_validation(train_matrix_df.as_matrix(), train_labels_df['candy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10 \n",
    "Report the mean accuracy, sensitivity and specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy:  0.866666666667\n"
     ]
    }
   ],
   "source": [
    "def report_mean( preds, trues):\n",
    "    flatten_pred = np.hstack(preds)\n",
    "    results = np.zeros(trues.unique().shape[0])\n",
    "    for i, label in enumerate(trues.unique()):\n",
    "        # indexes for such label\n",
    "        class_trues =  np.argwhere(trues == label).ravel()\n",
    "        # predicted label on such indexes\n",
    "        predicted = flatten_pred[class_trues]\n",
    "\n",
    "        results[i] = np.count_nonzero(predicted == label) / float(len(class_trues))\n",
    "    return results.mean()\n",
    "\n",
    "mean_accuracy = report_mean(pred, train_labels_df['candy'])\n",
    "print \"Mean Accuracy: \", mean_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Citrus\n",
      "Sensitivity:  0.9\n",
      "Specificity:  0.909090909091\n",
      "Halls\n",
      "Sensitivity:  0.833333333333\n",
      "Specificity:  0.818181818182\n"
     ]
    }
   ],
   "source": [
    "def report_sens_spec( pred, trues):\n",
    "    preds = np.hstack(pred)\n",
    "    classes = trues.unique()\n",
    "    # report sensitivity for each class\n",
    "    for label in classes:\n",
    "        print label.capitalize()\n",
    "        # indexes for such label\n",
    "        class_trues =  np.argwhere(trues == label).ravel()\n",
    "        class_falses =  np.argwhere(trues != label).ravel()\n",
    "\n",
    "        pred_trues = np.argwhere(preds == label).ravel()\n",
    "        pred_falses = np.argwhere(preds != label).ravel()\n",
    "\n",
    "        TP = sum([ 1. for p in pred_trues if p in class_trues ])\n",
    "        TN = sum([ 1. for p in pred_falses if p in class_falses ])\n",
    "        FN = sum([ 1. for p in pred_falses if p in class_trues ])\n",
    "        \n",
    "        sen = TP / (TP + FN)\n",
    "        spec = TN / (TN + FN)\n",
    "        print \"Sensitivity: \", sen\n",
    "        print \"Specificity: \", spec\n",
    "    \n",
    "report_sens_spec(pred, train_labels_df['candy'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11\n",
    "Extract the five most discriminating features (peaks) by using the Gini index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def most_discriminating( features_df, labels_df, top=5):\n",
    "    \"\"\"Uses gini index impurity as a splitting criteria, \n",
    "    only works for two classes. \n",
    "    Maximizes the information gain, so we return the \"top\" indexes\n",
    "    with the highest quality value, the closer to 1 the better\n",
    "    \n",
    "                          c        h\n",
    "                      +--------+--------+\n",
    "     c -> Citrus      |        |        |\n",
    "     h -> Halls     A | P(c|A) | P(h|A) |\n",
    "     c = 0            |        |        |\n",
    "     h = 1            +-----------------+\n",
    "                               |\n",
    "               +-----<-left(0)-+-right(1)->----+\n",
    "           c   |   h                       c   |  h\n",
    "      +-----------------+             +-----------------+\n",
    "      |        |        |             |        |        |\n",
    "    B | P(c|B) | P(h|B) |           C | P(c|C) | P(h|C) |\n",
    "      |        |        |             |        |        |\n",
    "      +--------+--------+             +--------+--------+\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    columns = features_df.shape[1]\n",
    "    labels_df = labels_df[['file', 'candy_id']].set_index('file')\n",
    "    qualities = np.zeros(columns)\n",
    "    \n",
    "    _left = 0\n",
    "    _right = 1\n",
    "\n",
    "    _c = 0\n",
    "    _h = 1\n",
    "\n",
    "    # globals\n",
    "    cases = float(labels_df['candy_id'].count()) # total cases\n",
    "\n",
    "    p_c_A = (labels_df['candy_id'] == 0).sum() / cases\n",
    "    p_h_A = 1.0 - p_c_A\n",
    "\n",
    "\n",
    "    for feature in range(columns):\n",
    "\n",
    "        branch_cases = np.zeros(2) # total on each branch\n",
    "        pi = np.zeros(2)     # proportion on each branch\n",
    "\n",
    "        split = np.array([\n",
    "            #c, h\n",
    "            [0, 0], #left\n",
    "            [0, 0]  #right\n",
    "        ])\n",
    "\n",
    "        for index, value in features_df[feature].iteritems():\n",
    "            split[value][labels_df.loc[index][0]] += 1\n",
    "\n",
    "        branch_cases[_left] = split[_left].sum()\n",
    "        branch_cases[_right] = split[_right].sum()\n",
    "        \n",
    "        if branch_cases[_left] == 0.0 or branch_cases[_right] == 0.0:\n",
    "            qualities[feature] = 0\n",
    "            continue\n",
    "        \n",
    "        pi[_left] = branch_cases[_left] / cases\n",
    "        pi[_right] = branch_cases[_right] / cases\n",
    "\n",
    "        p_c_B = split[_left][_c] / branch_cases[_left]\n",
    "        p_h_B = split[_left][_h] / branch_cases[_left]\n",
    "\n",
    "        p_c_C = split[_right][_c] / branch_cases[_right]\n",
    "        p_h_C = split[_right][_h] / branch_cases[_right]\n",
    "\n",
    "        gini_tree = 1.0 - (math.pow(p_c_A, 2) +  math.pow(p_h_A, 2))\n",
    "\n",
    "        gini_left = 1.0 - (math.pow(p_c_B, 2) +  math.pow(p_h_B, 2))\n",
    "        gini_right = 1.0 - (math.pow(p_c_C, 2) +  math.pow(p_h_C, 2))\n",
    "\n",
    "        quality = gini_tree - pi[_left] * gini_left - pi[_right] * gini_right\n",
    "\n",
    "        qualities[feature] = quality\n",
    "    return list(reversed(qualities.argsort()))[:top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 8, 63, 74, 32]\n"
     ]
    }
   ],
   "source": [
    "best_features = most_discriminating(train_matrix_df, train_labels_df)\n",
    "print best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 10]<--left -- + -- right-->[10, 2]\n"
     ]
    }
   ],
   "source": [
    "def test_splitting_on_feature(num = 0):\n",
    "    \"\"\"useful function to test splittings\"\"\"\n",
    "    left =  [0,0]\n",
    "    right = [0,0]\n",
    "    for i, side in enumerate(train_matrix_df[num]):\n",
    "        if int(side) == 0: \n",
    "            if train_labels_df.ix[i]['candy_id'] == 0:\n",
    "                left[0] += 1\n",
    "            else:\n",
    "                left[1] += 1\n",
    "        else:\n",
    "            if train_labels_df.ix[i]['candy_id'] == 0:\n",
    "                right[0] += 1\n",
    "            else:\n",
    "                right[1] += 1\n",
    "\n",
    "        #print \" %s goes to the %i side\" %(train_labels_df.ix[i]['candy'], side)\n",
    "\n",
    "    print str(left) + \"<--left -- + -- right-->\" + str(right)\n",
    "test_splitting_on_feature(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12\n",
    "\n",
    "Learn and plot/report a decision tree by using only these\n",
    "five best features/peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tree = tree.DecisionTreeClassifier()\n",
    "tree_train_features = train_matrix_df[best_features].as_matrix()\n",
    "tree_train_labels = train_labels_df['candy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tree = d_tree.fit(tree_train_features, tree_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.36.0 (20140111.2315)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"285pt\" height=\"316pt\"\n",
       " viewBox=\"0.00 0.00 285.00 316.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 312)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-312 281,-312 281,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<path fill=\"#399de5\" fill-opacity=\"0.164706\" stroke=\"black\" d=\"M154,-307.5C154,-307.5 68,-307.5 68,-307.5 62,-307.5 56,-301.5 56,-295.5 56,-295.5 56,-236.5 56,-236.5 56,-230.5 62,-224.5 68,-224.5 68,-224.5 154,-224.5 154,-224.5 160,-224.5 166,-230.5 166,-236.5 166,-236.5 166,-295.5 166,-295.5 166,-301.5 160,-307.5 154,-307.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"111\" y=\"-292.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">peak 13 &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"111\" y=\"-277.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.4959</text>\n",
       "<text text-anchor=\"middle\" x=\"111\" y=\"-262.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 22</text>\n",
       "<text text-anchor=\"middle\" x=\"111\" y=\"-247.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [10, 12]</text>\n",
       "<text text-anchor=\"middle\" x=\"111\" y=\"-232.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = halls</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M88.5,-180C88.5,-180 11.5,-180 11.5,-180 5.5,-180 -0.5,-174 -0.5,-168 -0.5,-168 -0.5,-124 -0.5,-124 -0.5,-118 5.5,-112 11.5,-112 11.5,-112 88.5,-112 88.5,-112 94.5,-112 100.5,-118 100.5,-124 100.5,-124 100.5,-168 100.5,-168 100.5,-174 94.5,-180 88.5,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-164.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-149.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 10</text>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-134.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 10]</text>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-119.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = halls</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M90.0073,-224.391C84.1335,-213.029 77.7369,-200.655 71.8166,-189.203\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"74.8912,-187.528 67.1898,-180.252 68.6729,-190.743 74.8912,-187.528\"/>\n",
       "<text text-anchor=\"middle\" x=\"59.6042\" y=\"-200.374\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.800000\" stroke=\"black\" d=\"M213.25,-187.5C213.25,-187.5 130.75,-187.5 130.75,-187.5 124.75,-187.5 118.75,-181.5 118.75,-175.5 118.75,-175.5 118.75,-116.5 118.75,-116.5 118.75,-110.5 124.75,-104.5 130.75,-104.5 130.75,-104.5 213.25,-104.5 213.25,-104.5 219.25,-104.5 225.25,-110.5 225.25,-116.5 225.25,-116.5 225.25,-175.5 225.25,-175.5 225.25,-181.5 219.25,-187.5 213.25,-187.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"172\" y=\"-172.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">peak 32 &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"172\" y=\"-157.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.2778</text>\n",
       "<text text-anchor=\"middle\" x=\"172\" y=\"-142.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 12</text>\n",
       "<text text-anchor=\"middle\" x=\"172\" y=\"-127.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [10, 2]</text>\n",
       "<text text-anchor=\"middle\" x=\"172\" y=\"-112.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = citrus</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M131.993,-224.391C136.594,-215.491 141.515,-205.971 146.277,-196.759\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"149.485,-198.174 150.969,-187.684 143.267,-194.96 149.485,-198.174\"/>\n",
       "<text text-anchor=\"middle\" x=\"158.554\" y=\"-207.805\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M151.5,-68C151.5,-68 74.5,-68 74.5,-68 68.5,-68 62.5,-62 62.5,-56 62.5,-56 62.5,-12 62.5,-12 62.5,-6 68.5,-0 74.5,-0 74.5,-0 151.5,-0 151.5,-0 157.5,-0 163.5,-6 163.5,-12 163.5,-12 163.5,-56 163.5,-56 163.5,-62 157.5,-68 151.5,-68\"/>\n",
       "<text text-anchor=\"middle\" x=\"113\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"113\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 10</text>\n",
       "<text text-anchor=\"middle\" x=\"113\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [10, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"113\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = citrus</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M150.198,-104.353C145.472,-95.5406 140.462,-86.2001 135.702,-77.3253\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"138.665,-75.445 130.854,-68.287 132.496,-78.7537 138.665,-75.445\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M265.25,-68C265.25,-68 194.75,-68 194.75,-68 188.75,-68 182.75,-62 182.75,-56 182.75,-56 182.75,-12 182.75,-12 182.75,-6 188.75,-0 194.75,-0 194.75,-0 265.25,-0 265.25,-0 271.25,-0 277.25,-6 277.25,-12 277.25,-12 277.25,-56 277.25,-56 277.25,-62 271.25,-68 265.25,-68\"/>\n",
       "<text text-anchor=\"middle\" x=\"230\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"230\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n",
       "<text text-anchor=\"middle\" x=\"230\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n",
       "<text text-anchor=\"middle\" x=\"230\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = halls</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M193.432,-104.353C198.079,-95.5406 203.004,-86.2001 207.683,-77.3253\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"210.881,-78.7651 212.449,-68.287 204.689,-75.5002 210.881,-78.7651\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f7e5f5d7e90>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check you have installed graphviz\n",
    "\n",
    "dot_data = tree.export_graphviz(d_tree, out_file=None,\n",
    "                                feature_names = ['peak ' + str(peak) for peak in best_features],\n",
    "                                class_names=train_labels_df['candy'].unique(),\n",
    "                                filled=True, rounded=True)  \n",
    "# two steps, one for saving\n",
    "graphviz.Source(dot_data, format='png').render(os.path.join(results_folder, \"tree\"))\n",
    "\n",
    "# second for showing\n",
    "graphviz.Source(dot_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stores the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Stores decission tree and random forests as pickle\n",
    "def store_model( model, name ):\n",
    "    name = name + \".pck\"\n",
    "    name = os.path.join(results_folder, name)\n",
    "    with open(name, 'w') as f:\n",
    "        pickle.dump(model, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    print \"File stored at \" + name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File stored at results/model_random_forests.pck\n"
     ]
    }
   ],
   "source": [
    "store_model(g_rf, \"model_random_forests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File stored at results/model_decision_tree.pck\n"
     ]
    }
   ],
   "source": [
    "store_model(d_tree, \"model_decision_tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File stored at results/model_k_means.pck\n"
     ]
    }
   ],
   "source": [
    "store_model(k_means, \"model_k_means\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g_rf = RandomForestClassifier()\n",
    "#g_rf = g_rf.fit(train_matrix_df[best_features].as_matrix(), train_labels_df['candy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
